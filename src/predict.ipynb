{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "import os.path\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(myModel, self).__init__()\n",
    "\n",
    "    inputDim, targetDim, channels = 3, 82, 64\n",
    "\n",
    "    self.layer0 = nn.Sequential(nn.Conv2d(inputDim, channels, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.layer1 = nn.Sequential(nn.Conv2d(channels, channels*2, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.layer2 = nn.Sequential(nn.Conv2d(channels*2, channels*4, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.layer3 = nn.Sequential(nn.Conv2d(channels*4, channels*4, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.layer4 = nn.Linear(channels*4, targetDim)\n",
    "\n",
    "  def forward(self, input) :\n",
    "    output = self.layer0(input)\n",
    "    output = self.layer1(output)\n",
    "    output = self.layer2(output)\n",
    "    output = self.layer3(output)\n",
    "    output = F.adaptive_avg_pool2d(output, (1,1)).view(output.size(0), -1)\n",
    "    output = self.layer4(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myModel(\n",
       "  (layer0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4): Linear(in_features=256, out_features=82, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = myModel()\n",
    "# model = torch.load('../model/bestModel.pth', map_location=device)\n",
    "model.load_state_dict(torch.load('../model/bestModel.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "data_dir  = 'extracted_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v:1558\n",
      ",:1906\n",
      "beta:2025\n",
      "cos:2986\n",
      "4:7396\n",
      "forward_slash:199\n",
      "prime:329\n",
      "G:1692\n",
      "mu:177\n",
      "ascii_124:1339\n",
      "{:376\n",
      "Delta:137\n",
      "7:2909\n",
      "sin:4293\n",
      "forall:45\n",
      "):14355\n",
      "lim:1675\n",
      "lambda:109\n",
      "9:3737\n",
      "k:3074\n",
      "pi:2332\n",
      "}:377\n",
      "z:5870\n",
      "geq:693\n",
      "A:12367\n",
      "(:14294\n",
      "i:5140\n",
      "p:2680\n",
      "f:3712\n",
      "o:449\n",
      "5:3545\n",
      "tan:2450\n",
      "T:3274\n",
      "j:1536\n",
      "l:1017\n",
      "phi:355\n",
      "C:5802\n",
      "y:9340\n",
      "neq:558\n",
      "R:2671\n",
      "]:780\n",
      "M:2476\n",
      "8:3068\n",
      "e:3003\n",
      "sum:2689\n",
      "0:6914\n",
      "q:1230\n",
      "b:8651\n",
      "!:1300\n",
      "u:1269\n",
      "=:13104\n",
      "leq:973\n",
      "div:868\n",
      "-:33997\n",
      "sqrt:8908\n",
      "rightarrow:1703\n",
      "2:26141\n",
      "w:556\n",
      "gamma:409\n",
      "ldots:609\n",
      "pm:802\n",
      "X:26594\n",
      "infty:1783\n",
      "exists:21\n",
      "lt:477\n",
      "1:26520\n",
      "d:4852\n",
      "N:10862\n",
      "gt:258\n",
      "theta:2796\n",
      "sigma:201\n",
      "6:3118\n",
      "+:25112\n",
      "[:778\n",
      "times:3251\n",
      "log:2001\n",
      "in:47\n",
      "int:2742\n",
      "alpha:2546\n",
      "3:10909\n",
      "H:1464\n",
      "S:1413\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "label = {}\n",
    "num = 0\n",
    "for className in listdir(join(data_path, \"extracted_images\")) :\n",
    "  print(f\"{className}:{len(listdir(join(data_path, 'extracted_images', className)))}\")\n",
    "  label[className] = num\n",
    "  num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = transforms.Compose([transforms.Resize((100,100)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                            ])\n",
    "trainset = torchvision.datasets.ImageFolder(root = data_path + 'extracted_images',\n",
    "                                            transform = trans)\n",
    "\n",
    "len(trainset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size = 338376\n",
      "test size = 37598\n",
      "\n",
      "training data set = 21149\n",
      "test data set = 2350\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.9 * len(trainset))\n",
    "test_size = len(trainset) - train_size\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(trainset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                         batch_size = 16,\n",
    "                         shuffle = True)\n",
    "\n",
    "test_loader = DataLoader(test_data,\n",
    "                         batch_size = 16,\n",
    "                         shuffle = True)\n",
    "\n",
    "print(f'train size = {train_size}\\ntest size = {test_size}')\n",
    "print('')\n",
    "print(f'training data set = {len(train_loader)}\\ntest data set = {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg loss: -5.6677672821788425, accuracy: 35527/37598 (94.49172828341933)\n"
     ]
    }
   ],
   "source": [
    "test_loss, correct = 0, 0\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model(data)\n",
    "    test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print(f'Avg loss: {test_loss}, accuracy: {correct}/{len(test_loader.dataset)} ({100 * correct/len(test_loader.dataset)})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math_ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
