{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "import os.path\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_imshow(title='image', img=None, figsize=(8 ,5)):\n",
    "    plt.figure(figsize=figsize)\n",
    " \n",
    "    if type(img) == list:\n",
    "        if type(title) == list:\n",
    "            titles = title\n",
    "        else:\n",
    "            titles = []\n",
    " \n",
    "            for i in range(len(img)):\n",
    "                titles.append(title)\n",
    " \n",
    "        for i in range(len(img)):\n",
    "            if len(img[i].shape) <= 2:\n",
    "                rgbImg = cv2.cvtColor(img[i], cv2.COLOR_GRAY2RGB)\n",
    "            else:\n",
    "                rgbImg = cv2.cvtColor(img[i], cv2.COLOR_BGR2RGB)\n",
    " \n",
    "            plt.subplot(1, len(img), i + 1), plt.imshow(rgbImg)\n",
    "            plt.title(titles[i])\n",
    "            plt.xticks([]), plt.yticks([])\n",
    " \n",
    "        plt.show()\n",
    "    else:\n",
    "        if len(img.shape) < 3:\n",
    "            rgbImg = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        else:\n",
    "            rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "        plt.imshow(rgbImg)\n",
    "        plt.title(title)\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(nn.Module) :\n",
    "  def __init__(self) :\n",
    "    super(myModel, self).__init__()\n",
    "\n",
    "    inputDim, targetDim, channels = 3, 82, 64\n",
    "\n",
    "    self.layer0 = nn.Sequential(nn.Conv2d(inputDim, channels, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.layer1 = nn.Sequential(nn.Conv2d(channels, channels*2, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.layer2 = nn.Sequential(nn.Conv2d(channels*2, channels*4, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.layer3 = nn.Sequential(nn.Conv2d(channels*4, channels*4, kernel_size=3, stride=1, padding=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.layer4 = nn.Linear(channels*4, targetDim)\n",
    "\n",
    "  def forward(self, input) :\n",
    "    output = self.layer0(input)\n",
    "    output = self.layer1(output)\n",
    "    output = self.layer2(output)\n",
    "    output = self.layer3(output)\n",
    "    output = F.adaptive_avg_pool2d(output, (1,1)).view(output.size(0), -1)\n",
    "    output = self.layer4(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myModel(\n",
       "  (layer0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4): Linear(in_features=256, out_features=82, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = myModel()\n",
    "# model = torch.load('../model/bestModel.pth', map_location=device)\n",
    "model.load_state_dict(torch.load('../model/bestModel.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(100, 100), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# def transform_image(img):\n",
    "trans = transforms.Compose([transforms.Resize((100,100)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                            ])\n",
    "\n",
    "print(trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "data_dir  = 'extracted_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v:1558\n",
      ",:1906\n",
      "beta:2025\n",
      "cos:2986\n",
      "4:7396\n",
      "forward_slash:199\n",
      "prime:329\n",
      "G:1692\n",
      "mu:177\n",
      "ascii_124:1339\n",
      "{:376\n",
      "Delta:137\n",
      "7:2909\n",
      "sin:4293\n",
      "forall:45\n",
      "):14355\n",
      "lim:1675\n",
      "lambda:109\n",
      "9:3737\n",
      "k:3074\n",
      "pi:2332\n",
      "}:377\n",
      "z:5870\n",
      "geq:693\n",
      "A:12367\n",
      "(:14294\n",
      "i:5140\n",
      "p:2680\n",
      "f:3712\n",
      "o:449\n",
      "5:3545\n",
      "tan:2450\n",
      "T:3274\n",
      "j:1536\n",
      "l:1017\n",
      "phi:355\n",
      "C:5802\n",
      "y:9340\n",
      "neq:558\n",
      "R:2671\n",
      "]:780\n",
      "M:2476\n",
      "8:3068\n",
      "e:3003\n",
      "sum:2689\n",
      "0:6914\n",
      "q:1230\n",
      "b:8651\n",
      "!:1300\n",
      "u:1269\n",
      "=:13104\n",
      "leq:973\n",
      "div:868\n",
      "-:33997\n",
      "sqrt:8908\n",
      "rightarrow:1703\n",
      "2:26141\n",
      "w:556\n",
      "gamma:409\n",
      "ldots:609\n",
      "pm:802\n",
      "X:26594\n",
      "infty:1783\n",
      "exists:21\n",
      "lt:477\n",
      "1:26520\n",
      "d:4852\n",
      "N:10862\n",
      "gt:258\n",
      "theta:2796\n",
      "sigma:201\n",
      "6:3118\n",
      "+:25112\n",
      "[:778\n",
      "times:3251\n",
      "log:2001\n",
      "in:47\n",
      "int:2742\n",
      "alpha:2546\n",
      "3:10909\n",
      "H:1464\n",
      "S:1413\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "label = {}\n",
    "num = 0\n",
    "for className in listdir(join(data_path, \"extracted_images\")) :\n",
    "  print(f\"{className}:{len(listdir(join(data_path, 'extracted_images', className)))}\")\n",
    "  label[className] = num\n",
    "  num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "trans = transforms.Compose([transforms.Resize((100,100)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                            ])\n",
    "\n",
    "def image_loader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = Image.open(image_name)\n",
    "    image = trans(image).float()\n",
    "    # image = Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
    "    return image.cuda()  #assumes that you're using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 45, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "im = cv2.imread(\"../data/output/2.jpg\")\n",
    "im = cv2.resize(im, dsize=(100, 100),interpolation=cv2.INTER_LINEAR)\n",
    "image_swap = np.swapaxes(im, 0,2)\n",
    "# image_swap = np.expand_dims(image_swap, axis=0)\n",
    "\n",
    "print(image_swap.shape)\n",
    "\n",
    "plt_imshow(\"title\", im)\n",
    "\n",
    "tensor = torch.from_numpy(image_swap).type(torch.cuda.FloatTensor)\n",
    "pred = model(tensor)\n",
    "\n",
    "probs = torch.nn.functional.softmax(pred, dim=1)\n",
    "conf, classes = torch.max(probs, 1)\n",
    "\n",
    "print(conf.item())\n",
    "print(classes.item())\n",
    "print(label[str(classes.item())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m im \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39m../data/output/2.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m im_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../data/output/1.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m img \u001b[39m=\u001b[39m image_loader(im_path)\n\u001b[1;32m      8\u001b[0m \u001b[39m# pred = model(img)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# print(pred)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# probs = torch.nn.functional.softmax(pred, dim=1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m# print(classes.item())\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# print('done')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[37], line 11\u001b[0m, in \u001b[0;36mimage_loader\u001b[0;34m(image_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(image_name)\n\u001b[1;32m     10\u001b[0m image \u001b[39m=\u001b[39m trans(image)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> 11\u001b[0m plt_imshow(image)\n\u001b[1;32m     12\u001b[0m \u001b[39m# image = Variable(image, requires_grad=True)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)  \u001b[39m#this is for VGG, may not be needed for ResNet\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m, in \u001b[0;36mplt_imshow\u001b[0;34m(title, img, figsize)\u001b[0m\n\u001b[1;32m     23\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     24\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(img\u001b[39m.\u001b[39;49mshape) \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m     26\u001b[0m         rgbImg \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_GRAY2RGB)\n\u001b[1;32m     27\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "im = cv2.imread(\"../data/output/2.jpg\")\n",
    "im_path = \"../data/output/1.jpg\"\n",
    "\n",
    "img = image_loader(im_path)\n",
    "\n",
    "# pred = model(img)\n",
    "# print(pred)\n",
    "# probs = torch.nn.functional.softmax(pred, dim=1)\n",
    "# conf, classes = torch.max(probs, 1)\n",
    "\n",
    "# print(conf.item())\n",
    "# print(classes.item())\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = transforms.Compose([transforms.Resize((100,100)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                            ])\n",
    "trainset = torchvision.datasets.ImageFolder(root = data_path + 'extracted_images',\n",
    "                                            transform = trans)\n",
    "\n",
    "len(trainset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size = 338376\n",
      "test size = 37598\n",
      "\n",
      "training data set = 21149\n",
      "test data set = 2350\n",
      "tensor([16,  2,  5,  1, 27, 77, 47,  9, 11, 79, 72,  8, 35, 16,  3,  5])\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.9 * len(trainset))\n",
    "test_size = len(trainset) - train_size\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(trainset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                         batch_size = 16,\n",
    "                         shuffle = True)\n",
    "\n",
    "test_loader = DataLoader(test_data,\n",
    "                         batch_size = 16,\n",
    "                         shuffle = True)\n",
    "\n",
    "print(f'train size = {train_size}\\ntest size = {test_size}')\n",
    "print('')\n",
    "print(f'training data set = {len(train_loader)}\\ntest data set = {len(test_loader)}')\n",
    "\n",
    "test = iter(test_loader)\n",
    "feature, label = next(test)\n",
    "\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: -5.683505429531121, accuracy: 35668/37598 (94.8667482312889)\n"
     ]
    }
   ],
   "source": [
    "test_loss, correct = 0, 0\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model(data)\n",
    "    test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print(f'Avg loss: {test_loss}, accuracy: {correct}/{len(test_loader.dataset)} ({100 * correct/len(test_loader.dataset)})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math_ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
