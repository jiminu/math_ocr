{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":337,"status":"ok","timestamp":1683524547756,"user":{"displayName":"minwoo ji","userId":"15275623901262771133"},"user_tz":-540},"id":"9_Yi-Sl-I8oM"},"outputs":[],"source":["from os import listdir\n","from os.path import join\n","import os.path\n","\n","from PIL import Image\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import torchvision\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchsummary import summary\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import random"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Dataset\n","## Kaggle Handwritten math symbols\n","\n","https://www.kaggle.com/datasets/xainano/handwrittenmathsymbols"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["already exist\n"]}],"source":["import gdown\n","import patoolib\n","\n","# google drive link\n","url       = 'https://drive.google.com/uc?id='\n","file_id   = '1iVt97n4fpFKUeTW93kNGMzbadRbHCjUf'\n","\n","# save path\n","data_path = '../data/'\n","data_dir  = 'extracted_images'\n","data_file = 'math_data.rar'\n","\n","if os.path.isdir(data_path+data_dir):\n","    print('already exist')\n","\n","# file download\n","elif not os.path.isfile(data_path+data_file):\n","    gdown.download(url + file_id, data_path+data_file, quiet=False)\n","    patoolib.extract_archive(data_path+data_file, outdir='../data/')\n","    \n","else:\n","    patoolib.extract_archive(data_path+data_file, outdir='../data/')\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1683524548592,"user":{"displayName":"minwoo ji","userId":"15275623901262771133"},"user_tz":-540},"id":"k3nQRmzQ4D7d","outputId":"b078ce0f-4108-4f8a-b742-e258600dab97"},"outputs":[{"name":"stdout","output_type":"stream","text":["using cuda\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'using {device}')\n","\n","random.seed(777)\n","torch.manual_seed(777)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)\n","\n","training_epochs = 25\n","batch_size = 256"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1329,"status":"ok","timestamp":1683524552022,"user":{"displayName":"minwoo ji","userId":"15275623901262771133"},"user_tz":-540},"id":"R3BypbDy_cb4","outputId":"2212d5a8-425c-4f92-ad67-53adaa957243"},"outputs":[{"name":"stdout","output_type":"stream","text":["pi\n","375974\n"]}],"source":["# image preprocessing\n","# grayscale, \n","# option: resize\n","trans = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=1),\n","    transforms.ToTensor() \n","    ])\n","trainset = torchvision.datasets.ImageFolder(root = data_path + 'extracted_images',\n","                                            transform = trans)\n","classes = trainset.classes\n","len(trainset.classes)\n","\n","print(trainset.classes[63])\n","print(len(trainset.targets))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1683524552024,"user":{"displayName":"minwoo ji","userId":"15275623901262771133"},"user_tz":-540},"id":"YosMttGILA9B","outputId":"d8596716-fa67-4ea3-81c9-9b95ba82853a"},"outputs":[{"name":"stdout","output_type":"stream","text":["train size = 300779\n","test size = 75195\n","\n","training data set = 1174\n","test data set = 293\n"]},{"data":{"text/plain":["(torch.Size([256, 1, 45, 45]), torch.Size([256]))"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_size = int(0.8 * len(trainset))\n","test_size = len(trainset) - train_size\n","\n","train_data, test_data = torch.utils.data.random_split(trainset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_data,\n","                         batch_size = batch_size,\n","                         shuffle = True,\n","                         drop_last = True)\n","\n","test_loader = DataLoader(test_data,\n","                         batch_size = batch_size,\n","                         shuffle = False,\n","                         drop_last = True)\n","\n","print(f'train size = {train_size}\\ntest size = {test_size}')\n","print('')\n","print(f'training data set = {len(train_loader)}\\ntest data set = {len(test_loader)}')\n","\n","\n","images, labels = next(iter(train_loader))\n","images.shape, labels.shape"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net,self).__init__()\n","        # output = ( input - filter(kernel) + 2 * padding) / stride ) + 1\n","        self.conv1 = nn.Conv2d(1, 64, 3, 1) # input, output, kernel_size, stride\n","        self.conv2 = nn.Conv2d(64, 128, 3, 1)\n","        self.dropout = nn.Dropout()\n"," \n","        # w*h*output\n","        self.fc1 = nn.Linear(9*9*128, 1000)\n","        self.fc2 = nn.Linear(1000, 82)\n","        \n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2, 2)\n","        x = self.dropout(x)\n","        x = x.view(-1, 9*9*128)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 43, 43]             640\n","            Conv2d-2          [-1, 128, 19, 19]          73,856\n","           Dropout-3            [-1, 128, 9, 9]               0\n","            Linear-4                 [-1, 1000]      10,369,000\n","            Linear-5                   [-1, 82]          82,082\n","================================================================\n","Total params: 10,525,578\n","Trainable params: 10,525,578\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 1.34\n","Params size (MB): 40.15\n","Estimated Total Size (MB): 41.50\n","----------------------------------------------------------------\n"]}],"source":["model = Net()\n","model.to(device)\n","summary(model, input_size=(1, 45, 45))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# define the negative log-likelihood loss\n","loss_func = nn.NLLLoss(reduction='sum')\n","\n","# define the Adam optimizer\n","opt = optim.Adam(model.parameters(), lr=1e-4)\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# define a helper function to compute the loss value per mini-batch\n","def loss_batch(loss_func, xb, yb, yb_h, opt=None):\n","    # obtain loss\n","    loss = loss_func(yb_h, yb)\n","    # obtain performance metric\n","    metric_b = metrics_batch(yb, yb_h)\n","    if opt is not None:\n","        loss.backward() # compute gradient\n","        opt.step() # update parameters\n","        opt.zero_grad() # set gradients to zero\n","    return loss.item(), metric_b\n","    \n","# define a helper function to compute the accurary per mini-batch\n","def metrics_batch(target, output):\n","    # optain output class\n","    pred = output.argmax(dim=1, keepdim=True)\n","    # compare output class with target class\n","    corrects = pred.eq(target.view_as(pred)).sum().item()\n","    \n","    return corrects\n","    \n","# define a helper fuction to compute the loss and metric values for a dataset\n","def loss_epoch(model, loss_func, dataset_dl, opt=None):\n","    loss = 0.0\n","    metric = 0.0\n","    len_data = len(dataset_dl.dataset)\n","    \n","    for xb, yb in dataset_dl:\n","        xb = xb.type(torch.float).to(device)\n","        yb = yb.to(device)\n","        # obtain model output\n","        yb_h = model(xb)\n","        \n","        loss_b, metric_b = loss_batch(loss_func, xb, yb, yb_h, opt)\n","        loss += loss_b\n","        if metric_b is not None:\n","            metric += metric_b\n","            \n","    loss /= len_data\n","    metric /= len_data\n","    return loss, metric"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# define train_val function\n","def train_val(epochs, model, loss_func, opt, train_dl, val_dl):\n","    for epoch in range(epochs):\n","        model.train() # convert to train mode\n","        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, opt)\n","        model.eval() # convert to evaluation mode\n","        with torch.no_grad():\n","            val_loss, val_metric = loss_epoch(model, loss_func, val_dl)\n","        accuracy = 100 * val_metric\n","        print('epoch: %d, train loss: %.6f, val loss: %.6f, accuracy: %.2f' %(epoch, train_loss, val_loss, accuracy))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 0, train loss: 1.051639, val loss: 0.476066, accuracy: 86.75\n","epoch: 1, train loss: 0.408563, val loss: 0.322830, accuracy: 90.44\n","epoch: 2, train loss: 0.296978, val loss: 0.253427, accuracy: 91.97\n","epoch: 3, train loss: 0.236852, val loss: 0.206183, accuracy: 93.63\n","epoch: 4, train loss: 0.195981, val loss: 0.170838, accuracy: 94.62\n","epoch: 5, train loss: 0.166162, val loss: 0.145606, accuracy: 95.45\n","epoch: 6, train loss: 0.142217, val loss: 0.126099, accuracy: 95.88\n","epoch: 7, train loss: 0.123769, val loss: 0.110348, accuracy: 96.51\n","epoch: 8, train loss: 0.108115, val loss: 0.095225, accuracy: 96.76\n","epoch: 9, train loss: 0.097351, val loss: 0.085227, accuracy: 97.11\n","epoch: 10, train loss: 0.086848, val loss: 0.078987, accuracy: 97.37\n","epoch: 11, train loss: 0.079232, val loss: 0.075723, accuracy: 97.37\n","epoch: 12, train loss: 0.073872, val loss: 0.066854, accuracy: 97.68\n","epoch: 13, train loss: 0.067967, val loss: 0.062936, accuracy: 97.89\n","epoch: 14, train loss: 0.063951, val loss: 0.060197, accuracy: 97.92\n","epoch: 15, train loss: 0.059530, val loss: 0.057637, accuracy: 98.01\n","epoch: 16, train loss: 0.056698, val loss: 0.054583, accuracy: 98.11\n","epoch: 17, train loss: 0.053258, val loss: 0.050709, accuracy: 98.21\n","epoch: 18, train loss: 0.050661, val loss: 0.051815, accuracy: 98.18\n","epoch: 19, train loss: 0.047864, val loss: 0.047361, accuracy: 98.31\n","epoch: 20, train loss: 0.046049, val loss: 0.047400, accuracy: 98.39\n","epoch: 21, train loss: 0.044215, val loss: 0.044463, accuracy: 98.41\n","epoch: 22, train loss: 0.042293, val loss: 0.042574, accuracy: 98.48\n","epoch: 23, train loss: 0.040991, val loss: 0.040279, accuracy: 98.51\n","epoch: 24, train loss: 0.039186, val loss: 0.042695, accuracy: 98.52\n"]}],"source":["train_val(training_epochs, model, loss_func, opt, train_loader, test_loader)"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[],"source":["from datetime import datetime\n","\n","now = datetime.now()\n","\n","torch.save(model.state_dict(), f\"../model/model_{now.year}{now.month}{now.day}{now.hour}{now.minute}{now.second}.pth\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Reference\n","\n","https://deep-learning-study.tistory.com/459"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOyrOAh6frqFiDdErhMbJOG","gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
